
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, minimum-scale=1, initial-scale=1, user-scalable=yes">
    <!-- REMOVE THIS METATAG on public launch! -->
    <meta name="robots" content="noindex">

    <title>Wide+Deep learning tutorial with TensorFlow and Game of Thrones</title>
    <meta name="description" content="who-will-die-got-tensorflow-codelab description">

    <!-- See https://goo.gl/OOhYW5 -->
    <link rel="manifest" href="/manifest.json">

    <script src="/bower_components/webcomponentsjs/webcomponents-lite.js"></script>

    <link rel="import" href="/bower_components/codelab-components/google-codelab-elements.html">
    <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Source+Code+Pro:400|Roboto:400,300,400italic,500,700|Roboto+Mono">
    <style>
      body {
        font-family: "Roboto",sans-serif;
        background-color: #e0e0e0;
      }
    </style>
  </head>
  <body>

  <google-codelab 
      title="Discover what GOT Character will die next using TensorFlow"
      environment="web"
      feedback-link="https://github.com/codelab-tf-got/codelab-tf-got.github.io/issues"
      last-updated="2016-12-01">

    <!-- STEP 1 -->
    <google-codelab-step 
      label="Presentation" 
      step="1" 
      duration="5">
      <p>

      
      <img src="0_Logo.jpg" alt="TensorFlow Game of Thrones"> 
             <a href="http://tensorflow.org/" target="_blank" rel="noopener">TensorFlow</a> is a an open source library for numerical computation, specializing in machine learning applications. In this codelab, you will learn how to install and run TensorFlow on a single machine, and will predict deaths on Game of Thrones data using the tutorial Wide+Deep Learning Network.</p>
      <h2>What are we going to be building?</h2>
      <p>
      This codelab presents wide+deep learning model execution taking into account Game of Thrones data for Death classification & prediction .
The aim of this Codelab is to dig into wide+deep neural network model  to combine the benefits of memorization+generalization models, in which wide model is directly relevant to features and deep model improves the diversity of recommended systems. </p>
      <p>
  The wide+deep learning tutorial comes within census data so we have been working with an analogous dataset taking into consideration Game of Thrones .</p>
      <h2 class="checklist">What You&#39;ll Learn</h2>
      <p>
      In the next sections you will know  how the dataset works ,how to implement the wide+deep learning model  and finally some conclusions about the experimentation with the model, and more in detail . Besides and listed, you will learn how to:</p> 
      <ul class="checklist">
        <li>Familiarize yourself with Tensorflow  </li>
        <li>How to select features for the wide part: choose the sparse base columns and crossed columns you want to use.</li>
        <li>Select features for the deep part: choose the continuous columns, the embedding dimension for each categorical column, and the hidden layer sizes.</li>
        <li>How to design the Wide+Deep Learning TensorFlow model </li>
        <li>Put them all together in a Wide & Deep model (DNNLinearCombinedClassifier).</li>
      </ul>

      <h2 class="checklist">What You&#39;ll Need</h2>
      <ul>
        <li>A computer connected to the internet with Python2.7 installed </li>
        <li>The libraries sklearn, pandas , numpy installed </li>
        <li>A basic understanding of python and neural nets</li>
        <li>A fast computer running OS X or Linux</li>
        <li>A fair amount of time</li>
      </ul>
      
          <h2 class="checklist">The Goal</h2>
      <ul>
        <li>To made a classification model </li>
        <li>Predict the next character death probability in Game of Thrones</li>
      </ul>

      <aside class="special">
        <p>
        <strong>Note:</strong>  This codelab has quiet periods of downloading and training. During those times, it might be a fun idea to play with the <a href="http://playground.tensorflow.org/" target="_blank" rel="noopener">TensorFlow Playground to learn more about neural net design</a>
        </p>
      </aside>
      <img src="Data is coming!.png" alt="TensorFlow Game of Thrones">
    </google-codelab-step>
    <google-codelab-step 
      label="Visualization behind GoT DataSet" 
      step="2" 
      duration="10">
      <p>
      <h2>The data powering the CodeLab</h2>
      <img src="1_Comic.png" alt="TensorFlow JohnSnow & Sam correlation"> 
      <p>
      The GoT dataset was compiled from a <a href="https://www.kaggle.com/" target="_blank" rel="noopener">kaggle</a> dataset and transformed to offer more information using Game of Thrones wiki . 
      Before going into a deeper data analysis, we would like to offer a view about the power of search with Answer the public tool. Using this visualization about the main five W some questions could be underlined about game of Thrones using  the searches in US and UK </p> 
      <p>
      These visualization flashlights the public interest about Game of Thrones deaths related to WHY,WHAT,WHEN and HOW. In most of the searches there comes an interest about why all characters die, in which book each character die or in which TV season as well as searches about video compilations . Also we might  find comparisons to Walking Death. </p>
      <p>In a first general approach, we can see that searches about Game of Thrones Deaths are related to which deaths are packaged in each book or season. 
      The question ‘HOW’ might offer us a more practical approach about  people searching for compilation of deaths, Youtube videos about it. </p>
      <img src="2_question-visualisation.gif" alt="The five 5`ws about searches in Game of Thrones">     
      <h2>Data analysis</h2>
      <p>
  During this 0 point  we will serve as company for Tensorflow Codelab based on Game of Thrones Data, in order to provide a Neural Network model to classify the probability of Death of Game of Thrones characters with wide+deep model .
There is some data theory we will dive in when implementing the model, but first we will dig a little bit in the data in order to know more about the behaviour of our dataset </p>
      <p>
<p><a href="https://github.com/codelab-tf-got/code/archive/master.zip" target="_blank"><paper-button class="colored" raised><iron-icon icon="file-download"></iron-icon>Download source code</paper-button></a></p>
      <p>You can download the data from the button below. The original dataset has been released in Kaggle and we have been filling the information in Game of Thrones wiki focusing on title, culture . </p>
      <p>
      <img src="Table1.jpg" alt="Data">
   
In one first approach of the dataset we extract the following useful information about the dataset, wich we consider a significant first approach for finding correlations and relationships in between variables </p>
 
      <p> NUMBER OF CHARACTERS :  1946 </p>
      <p>  MEDIAN OF  AGE : 27 </p>
      <p>CORRELATION BETWEEN Number of Death Relationships and Popularity : 0.663 </p>
      <p>
  Here we have some graphics that show correlation among data , having into account that most of them show relationships in between popularity and other characteristics .
      <img src="1_CultureGOT.png" alt="Culture Analysis">  Game of Thrones character ecosystem shows a diverse culture approach that prints a diverse atmosphere , without a doubt it really brings to the table a rich atmosphere to enjoy. Among all cultures, the most significant are Valyrian - as House Targaryen members- , Northmen -like watchmen -that has the highest value in culture with 143 characters,  and Andals - like House Lannister. 
      <img src="histogram_pop.jpg" alt="Histogram of popularity">On this first approach of Histogram of popularity , more than 750 characters , about 40 % are ranged with 0 popularity ; being the most popular character listed – less than 20 , about a 1.02 % - the following, described together within .
However, the median of popularity is 0.03344 </p>
      <p>
 <img src="3_Tensorflow_PDr.gif" alt="Popularity VS number of Death Relations">
With this graph we would like to enlighten us to solve the following questions
      <p>Is there a relationship in between the popularity of a character and the number of death Characters? </p>
<p>As you can see the popularity listed as 1 there is a constant interval that goes from 1 to 10 deaths. Also there is presence in more than 15 deaths </p>

<p>On the Y axis we can find a score that goes from 0 to 1 and gives us an idea of the popularity of the current character and scored on the X axis the number of death relationships that go from 0 to 14. The visualization of this graph drops some conclusions upon us : </p>
    <p>0) Most popularity characters are ranked from 0 to 0.6 and have 0 dead relationships . </p>
    <p>1) We could draw an exponential classify curve that give us a certain pattern and given the following conclusions .</p>
    <p>--Most of unpopular characters have  no dead relationships </p>
    <p>--There is a linear incremental number of dead relationships once the character is very popular </p>
    <p>--A very popular character with a high number of dead relations can be considered an outlier . </p>

     <h2>"Once you are very popular, there 're seems to be a linear incremental pattern of Death Relationship</h2>
     <p>As we dig into the data, so do we within the question we actually want to solve...How is popularity related to Death in Game of Thrones?. </p>
     <img src="2_Comic.png" alt="you know nothing sql">
     <p>This first approach has been great ! Now let´s move into installing Tensorflow and have a deeper understanding with wide+deep learning model to gain more knowledge  . </p>
     </google-codelab-step>
    <!-- STEP 3 -->
    <google-codelab-step  
      label="Installing Tensorflow V1" 
      step="1" 
      duration="10">
      <p>
      <h2>Instalation of Tensorflow</h2>
      <p>Follow installation instructions for the following platforms </p>
      <p>Linux</p> <a href="https://www.tensorflow.org/install/install_linux" target="_blank" rel="noopener">linux</a>
      <p>Mac</p> <a href="https://www.tensorflow.org/install/install_mac" target="_blank" rel="noopener">Mac</a>
      <p>Windows</p> <a href="https://www.tensorflow.org/install/install_windows" target="_blank" rel="noopener">Windows</a>
      <p>From Source</p> <a href="https://www.tensorflow.org/install/install_sources" target="_blank" rel="noopener">From Source</a>
      <p>Here we cover Linux installation but you can see different . So , since the v1 release, you can type </p>
      <pre><code>
$ pip install tensorflow      # Python 2.7; CPU support (no GPU support)
 $ pip3 install tensorflow     # Python 3.n; CPU support (no GPU support)
 $ pip install tensorflow-gpu  # Python 2.7;  GPU support
 $ pip3 install tensorflow-gpu # Python 3.n; GPU support
      </code></pre>
      <p>Great! Now you should have your instalation complete. You can test in your console typing in python</p>
      <pre><code>
      >>> import tensorflow
      >>> hello = tf.constant('Hello, Tensorflow!')
      >>> sess = tf.Session()
      >>> sess.run(hello)
      'Hello, Tensorflow!'
      </code></pre>      
    </google-codelab-step>      
    <google-codelab-step  
      label="Downloading the CodeLab" 
      step="4" 
      duration="10">
      <p>
      <h2>Downloading the CodeLab</h2>  
      <p><a href="https://github.com/codelab-tf-got/code/archive/master.zip" target="_blank"><paper-button class="colored" raised><iron-icon icon="file-download"></iron-icon>Download source code</paper-button></a></p>      
      <p>You can download the code and the data below. We suggest you to download both and put them in the same folder .  We will be explaining afterwards in each model which part of the codes matches with each part of wide + deep learning model . 
    Once you have it downloaded into your computer, you can play with it . </p>              
      <h2 class="checklist">CodeLab Structure</h2>
      <ul>
      <img src="Download_thecodelab.jpg" alt="network">        
        <li>Download the code and the data_set and put it on a folder. 
          <p>It should contain the file wide+deep_Tensorflow_GOT and the file GOT_data.csv </p> </li>
        <li>Open the file and change the path in your dataset :
          <p>data_set = ‘your_path_here’ </p> </li>
        <li>In console, execute the program  :
          <p>~ $ python 'program' --training_mode learn_runner --model_dir /Base directory for output models --model_type 'wide_n_deep' --steps 200 </p></li>
        <li>In console, execute Tensorflow  :
          <p>~ $ tensorboard --logdir =/tmp/model/ </p> </li>
      </ul>      
    </google-codelab-step>     
    <google-codelab-step  
      label="Network Structure" 
      step="5" 
      duration="10">
      <p>
      <h2>Network Structure</h2>    
      <p> During the next session we will explain the architecture of the Wid+Deep learning model having into consideration the published paper by Google. We also recommend the <a href="https://www.youtube.com/watch?v=NV1tkZ9Lq48&list=PLOU2XLYxmsIKGc_NBoIhTn2Qhraji53cv&index=17" target="_blank" rel="noopener">talk</a> given by Heng-Tze Cheng at Tensorflow Dev Summit 2017 . </p>
      <img src="Wide+DeepLearning.gif" alt="network">  
      <p> Image from wide+deep tutorial </p>
      <p> The aim of this model is to combine the benefits of memorization+generalization models, in wich wide model is directly relevant to features and deep model improves the diversity of recommended systems. 
The abstraction of concepts in this text comes from the paper wide + deep learning for recommender systems  <a href="https://arxiv.org/pdf/1606.07792.pdf" target="_blank" rel="noopener">paper</a></p>     
      <p>With less feature engineering, deep neural networks can generalize better to unseen feature combinations through low-dimensional dense embeddings learned for the sparse features. However, deep neural networks with embeddings can over-generalize
        and recommend less relevant items when the user-item interactions are sparse and high-rank. </p>
      <p>Wide+Deep learning combines the benefits the Memorization and generalization , which is a current challenge for learning systems. Each part of the nets shows it challenges as well, so in Wide net we can find crossed columns and in deep learning we can find embeddings as the most significant concepts operating in each part of the Network . </p>
      <img src="MEME_george.jpg" alt="meme_Stark">
      <h2>Base Features</h2>
      <p>Categorical variables are also known as discrete or qualitative variables. Categorical variables can be further categorized as either nominal, ordinal or dichotomous. Nominal variables are variables that have two or more categories, but which do not have an intrinsic order.
Continuos variables are those that refers to continuous values such as numbers </p> 
      <pre><code>
CATEGORICAL_COLUMN_NAMES = only_existing([
    'male',
    'culture',
    'mother',
    'father',
    'title',
    'heir',
    'house',
    'spouse',
    'numDeadRelations',
    'boolDeadRelations',
], COLUMNS)

CONTINUOUS_COLUMNS = only_existing([
  'age',
  'popularity',
  'dateOfBirth',
], COLUMNS)

      </code></pre>
    </google-codelab-step>   
    <google-codelab-step  
      label="Network Structure : Linear Classifier" 
      step="5.1" 
      duration="10">
      <h2>Linear classiffier: Memorization</h2> 
      <p>Memorization -Wide Model- Comes with learning the frequent co-ocurrence of features and exploiting the correlation available in the historical data. It is directly relevant to features . It can be achieved effectively using cross-product transformations over sparse features. Memorization is directly relevant to features. </p>
      <p>The linear classifier digs into continuous features . In a practical approach you could say that this model is suitable for continuous -often numerical data- which already can be made some sense of. This model needs manual feature engineering for crossed relationships between columns. </p>
<p>Beyond you can find how we approach the linear classifier in the exercise : 
We define the linear variables in the columns
We execute the linear classifier 

Here the design of the net comes with the combination of features that can combine the information in order to offer a suitable conclusion </p> 
      <img src="WideDEF.gif" alt="crossing_narrow_sea">
      <p> Image from wide+deep tutorial </p>
      <pre><code>
  if FLAGS.model_type == "wide":
    m = tf.contrib.learn.LinearClassifier(model_dir=model_dir,
                                          feature_columns=wide_columns)
      </code></pre> 
    </google-codelab-step>
    <google-codelab-step  
      label="Network Structure : Deep Layer" 
      step="5.2" 
      duration="10">      
      <h2>Deep layer</h2>
      <img src="Deep.gif" alt="netkork">
      <p> Image from wide+deep tutorial </p>
      <p>Generalization - Deep Model-  the model is a Feedfoward neural network that works with categorical features . there exist Transitivity of correlation and explores feature combinations that have never or rarely occurred in the past. It improves the diversity of recommended items . This generalization can be added by using features that are less granular . 
So at the end this model is great for combining two different models of classification using neural Networks. You can see how this model has been working with </p> 
      <h2>Deep layer</h2>  
      <pre><code>
  elif FLAGS.model_type == "deep":
    m = tf.contrib.learn.DNNClassifier(model_dir=model_dir,
                                       feature_columns=deep_columns,
                                       hidden_units=[100, 50])
      </code></pre> 
    </google-codelab-step>
    <google-codelab-step
      label="Network Structure : Combining wide+deep learning model" 
      step="5.3" 
      duration="10">      
      <h2>Combining wide and deep learning model into one</h2>      
      <p>The wide models and deep models are combined by summing up their final output log odds as the prediction, then feeding the prediction to a logistic loss function. All the graph definition and variable allocations have already been handled for you under the hood, so you simply need to create a DNNLinearCombinedClassifier: </p>
      <p> In this case, there are two layers with 100 and 50 neurons each. You can select your own number of layers and neurons </p>
      <pre><code>
  else:
    m = tf.contrib.learn.DNNLinearCombinedClassifier(
      model_dir=model_dir,
      linear_feature_columns=wide_columns,
      dnn_feature_columns=deep_columns,
      dnn_hidden_units=[100, 50],
      fix_global_step_increment_bug = True,
    )
  return m  
      </code></pre>
    </google-codelab-step>
    <google-codelab-step  
      label="Optimizers" 
      step="5.4" 
      duration="10"> 
      <h2>Optimizers</h2>
      <img src="3_Comic.png" alt="cercei_queen">
      <p>The Optimizer base class provides methods to compute gradients for a loss and apply gradients to variables. A collection of subclasses implement classic optimization algorithms such as GradientDescent and Adagrad. </p>
Optimizers are a detailed part of neural net design that can offer a real performance difference among the neural net models. You can find  documentation about Tensorflow optimizers <a href="https://www.tensorflow.org/api_guides/python/train" target="_blank" rel="noopener">here</a>
      <p>If we had to underline a concept about optimizers it would be the learning_rate .We could define the learning_rate as a value used by the learning algorithm to determine how quickly the weights are adjusted. It determines the adquisition time for neurons with weights that are trained using the algortihm. </p>
      <p>Bellow we describe the parameters and the main characteristics of the optimizers wich you can try in the model. Note that the model has been defined as bellow and optimizers have been changed for that model : </p>
      <img src="optimizer.jpg" alt="cercei_queen">
    </google-codelab-step>
    <google-codelab-step  
      label="Comparisons and Conclusions" 
      step="6" 
      duration="10">     
      <h2>Comparison</h2>
      <p>The code has been executed taking into account serveral models for the same dataset ; You can find the table bellow in wich we print the accuracy and other significant data about each part of the model :
Please, take into account that all the modifications are inside m= tf.contrib.learn.DNNLinearCombinedClassifier tensorflow class and the design has been modeled with the wide and the deep settings . 
Please, to know more about this function visit the awesome <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/learn/DNNLinearCombinedClassifier" target="_blank" rel="noopener">documentation.</a></p>

      <h2>Conclusions</h2> 
      <p>Wide+deep learning is great for large scale datasets that take into account both categorical and continuous features that include a numerical and embeding form . Having a self critical mode, we might have used a more large dataset with more Game of Thrones characters  although the nature of the dataset is great for continuous and categorical clasification.
      <p>The accuracy of the model changes by design taking into account the hidden units of the model, the activation function, and the optimizers. Having more or less layers and hidden units does not imply that the functioning of the model might be better or worse . </p>
      <p>Choosing the wide and deep learning settings carefully taking into account the problems they usually solve is also a useful task to take , as well as the learning rate. </p>
      <p>The best result of the model is pasted with the accuracy as follows : </p>


       <p>You can help us with the results of changing the model, generalizing in hypothesis : </p>
        
<p>In the model, if you increase the hidden layers and combine the number of neurons , the accuracy of the model increases or decreases? . </p>
Please, fill your model conclussions in this <a href="https://docs.google.com/forms/d/1QLNq6nxWIJRuO-JiK3wgnLaeW2X3wbFS1edzzj59cLQ/edit" target="_blank" rel="noopener">Form</a>
<p>Take this feedback form to tell us more about how useful it was and dig into it if you want to know more </p>   

      <img src="5_Comic.png" alt="TensorFlow Game of Thrones"> 
       <p>Code :  </p>   <a href="https://github.com/ssaavedra" target="_blank" rel="noopener">Santiago Saavedra</a> 
       <p>Codelab documentation and images : </p>   <a href="https://github.com/SoyGema" target="_blank" rel="noopener">Gema Parreño</a> 
      <p>Special thanks to  : </p>   <a href="https://github.com/Baenans" target="_blank" rel="noopener">Fran</a> 
       <p>Special thanks to  : </p>   <a href="https://github.com/flipper83" target="_blank" rel="noopener">Flipper83</a>      
</html>
